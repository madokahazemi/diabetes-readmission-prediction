import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import chi2_contingency


# Modelling
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
#from sklearn.metrics import mean_squared_error, r2_score,classification_report, confusion_matrix, roc_auc_score
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor, RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import SVR, SVC
from sklearn.linear_model import LinearRegression, Ridge,Lasso, LogisticRegression, RidgeClassifier
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.model_selection import RandomizedSearchCV
from sklearn.feature_selection import RFE
#from catboost import CatBoostRegressor
#from xgboost import XGBRegressor
import warnings


#Load dataset
pd.options.display.max_columns = None
df = pd.read_csv('/Users/mady/Library/Mobile Documents/com~apple~CloudDocs/DS project/readmission-prediction/data/diabetic_data.csv')
df.head()

# Display basic information about the dataset
df.info()

# Display summary statistics of the dataset
df.describe(include='all')

# Display summary statistics only for numeric columns
df.describe()

# Find the unique values in each column
for column in df.columns:
    print(column)
    print(df[column].unique())
    
# Dropping examide and citoglipton columns as they have only one unique value
df.drop(['examide', 'citoglipton'], axis=1, inplace=True)    

# Remove ? values from the dataset
df.replace('?', np.nan, inplace=True)

object_cols = df.select_dtypes(include=['object']).columns

for col in object_cols:
    unique_values = df[col].unique()
    print(f"Column: {col}")
    print(f"Unique Values: {unique_values[:10]}")  # Displaying first 10 unique values for brevity
    print(f"Number of Unique Values: {len(unique_values)}")
    print()

# Display & of missing values in each column as percentage
missing_values = df.isnull().sum() / len(df) * 100
missing_values

##Do we drop columns with >80% missing values? Or do we impute them?


# Convert columns to 'category' dtype
categorical_cols = [
    'race', 'gender', 'age', 'weight', 'max_glu_serum', 'A1Cresult', 'payer_code', 
    'medical_specialty', 'readmitted', 'change', 'diabetesMed'
]

# Create hierarchy for the 'category' dtype
age_hierarchy = ['[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)', '[50-60)', '[60-70)', '[70-80)', '[80-90)', '[90-100)']
weight_hierarchy = ['[0-25)', '[25-50)', '[50-75)', '[75-100)', '[100-125)', '[125-150)', '[150-175)', '[175-200)', '>200']
max_glu_serum_hierarchy = ['None', 'Norm', '>200', '>300']
A1Cresult_hierarchy = ['None', '>7', '>8', 'Norm']


# Create a dictionary to store the hierarchy for each column
hierarchy_dict = {
    'age': age_hierarchy,
    'weight': weight_hierarchy,
    'max_glu_serum': max_glu_serum_hierarchy,
    'A1Cresult': A1Cresult_hierarchy
}

# Convert columns to 'category' dtype with hierarchy
for col in categorical_cols:
    if col in hierarchy_dict:
        df[col] = pd.Categorical(df[col], categories=hierarchy_dict[col], ordered=True)
    else:
        df[col] = df[col].astype('category')

medication_cols = [
    'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 
    'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 
    'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 
    'insulin', 'glyburide-metformin', 'glipizide-metformin', 
    'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone'
]

for col in medication_cols:
    df[col] = df[col].astype('category')
    
    
# Convert binary columns to numeric
binary_cols = ['change', 'diabetesMed']

label_encoder = LabelEncoder()
for col in binary_cols:
    df[col] = label_encoder.fit_transform(df[col])
    
# Mapping of ICD-9 codes to categories
icd9_to_category = {
    'Circulatory': [str(i) for i in range(390, 460)] + ['785'],
    'Respiratory': [str(i) for i in range(460, 520)] + ['786'],
    'Digestive': [str(i) for i in range(520, 580)] + ['787'],
    'Diabetes': ['250'],
    'Injury': [str(i) for i in range(800, 1000)],
    'Musculoskeletal': [str(i) for i in range(710, 740)],
    'Genitourinary': [str(i) for i in range(580, 630)] + ['788'],
    'Neoplasms': [str(i) for i in range(140, 240)],
    'Other': ['780', '781', '784'] + [str(i) for i in range(790, 800)],
    'Endocrine': [str(i) for i in range(240, 280) if i != 250],
    'Skin': [str(i) for i in range(680, 710)] + ['782'],
    'Infectious': [str(i) for i in range(1, 140)],
    'Mental': [str(i) for i in range(290, 320)],
    'External': ['E'] + ['V'],
    'Blood': [str(i) for i in range(280, 290)],
    'Nervous': [str(i) for i in range(320, 360)],
    'Pregnancy': [str(i) for i in range(630, 680)],
    'Sense': [str(i) for i in range(360, 390)],
    'Congenital': [str(i) for i in range(740, 760)]
}

# Function to map ICD-9 code to category
def map_icd9_to_category(icd9_code):
    if pd.isna(icd9_code):
        return 'Unknown'
    for category, codes in icd9_to_category.items():
        if any(icd9_code.startswith(code) for code in codes):
            return category
    return 'Unknown'

# Apply mapping to diagnosis columns
df['diag_1_category'] = df['diag_1'].apply(map_icd9_to_category)
df['diag_2_category'] = df['diag_2'].apply(map_icd9_to_category)
df['diag_3_category'] = df['diag_3'].apply(map_icd9_to_category) 


# Check for missing values
missing_values = df.isnull().sum()
print(missing_values[missing_values > 0])
## How to handle the missing values?

#display histograms for all columns
df.hist(figsize=(20, 20), bins=30, edgecolor='black')


## Exploring relationships between features

# Function to plot count plots
def plot_countplot(ax, df, col, hue):
    sns.countplot(x=col, hue=hue, data=df, edgecolor='black', ax=ax, order=df[col].value_counts().index)
    ax.set_title(f'{hue} by {col}')
    ax.tick_params(axis='x', rotation=45)
    
    
# Function to normalize data for readmission rates
def normalize_data(df, group_col):
    normalized_df = df.groupby([group_col, 'readmitted'], observed=False).size().unstack().fillna(0)
    normalized_df = normalized_df.div(normalized_df.sum(axis=1), axis=0)
    return normalized_df

# Function to plot normalized readmission rates
def plot_normalized_readmission(ax, normalized_df, group_col):
    normalized_df.plot(kind='bar', stacked=True, edgecolor='black', ax=ax)
    ax.set_title(f'Normalized Readmission Rates by {group_col}')
    ax.set_ylabel('Proportion')
    ax.tick_params(axis='x', rotation=45)


# Function to display count and normalized plots side by side
def display_plots_side_by_side(df, cols, plot_func):
    for col in cols:
        fig, axs = plt.subplots(1, 2, figsize=(20, 6))
        
        plot_func(axs[0], df, col, outcome_col)
        
        normalized_df = normalize_data(df, col)
        plot_normalized_readmission(axs[1], normalized_df, col)
        
        plt.tight_layout()
        plt.show()
    
# Define the outcome column
outcome_col = 'readmitted'

# Outcome vs. Patient Demographics
demographic_cols = ['race', 'gender', 'age']
display_plots_side_by_side(df, demographic_cols, plot_countplot)

# Outcome vs. Admission and Discharge Details
admission_discharge_cols = ['admission_type_id', 'discharge_disposition_id', 'admission_source_id']
display_plots_side_by_side(df, admission_discharge_cols, plot_countplot)

# Outcome vs. Hospital Stay Details
stay_details_cols = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications']
for col in stay_details_cols:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=outcome_col, y=col, data=df)
    plt.title(f'{col} by {outcome_col}')
    plt.xticks(rotation=45)
    plt.show()
    

# Hospital history features vs. outcome
history_cols = ['number_outpatient', 'number_emergency', 'number_inpatient']
for col in history_cols:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=outcome_col, y=col, data=df)
    plt.title(f'{col} by {outcome_col}')
    plt.xticks(rotation=45)
    plt.show()

# Outcome vs. Change and DiabetesMed
binary_cols = ['change', 'diabetesMed']
display_plots_side_by_side(df, binary_cols, plot_countplot)

# Outcome vs. diagnosis categories
diagnosis_cols = ['diag_1_category', 'diag_2_category', 'diag_3_category']
display_plots_side_by_side(df, diagnosis_cols, plot_countplot)

# Pairplot for Numerical Variables
numerical_cols = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient']
sns.pairplot(df[numerical_cols + ['readmitted']], hue='readmitted')
plt.show()

# Heatmap for each categorical variable
new_categorical_cols = ['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'change', 'diabetesMed', 'diag_1_category', 'diag_2_category', 'diag_3_category']

for i, col1 in enumerate(new_categorical_cols):
    for col2 in new_categorical_cols[i+1:]:
        plt.figure(figsize=(12, 8))
        contingency_table = pd.crosstab(df[col1], df[col2])
        sns.heatmap(contingency_table, annot=True, fmt="d", cmap="YlGnBu")
        plt.title(f'Frequency of {col1} and {col2}')
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        plt.show()
        
display_plots_side_by_side(df, new_categorical_cols, plot_countplot)
        
from statsmodels.graphics.mosaicplot import mosaic

for i, col1 in enumerate(new_categorical_cols):
    for col2 in new_categorical_cols[i+1:]:
        plt.figure(figsize=(12, 8))
        mosaic(df, [col1, col2], title=f'Mosaic plot of {col1} and {col2}')
        plt.xticks(rotation=45)
        plt.show()
        
# Heatmap for numerical variables
# Create Correlation Matrix
# Make readimitted a numerical variable
df['num_readmitted'] = df['readmitted'].map({'<30': 1, '>30': 1, 'NO': 0})
plt.figure(figsize=(12, 8))
corr_matrix = df[['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'num_readmitted', 'diabetesMed', 'change']].corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix for Numerical Variables')
plt.show()


def chi_square_test(df, col1, col2):
    contingency_table = pd.crosstab(df[col1], df[col2])
    chi2, p, dof, expected = chi2_contingency(contingency_table)
    return chi2, p

# Perform Chi-Square Test for each categorical variable against 'readmitted'
results = []
for col in new_categorical_cols:
    chi2, p = chi_square_test(df, col, 'readmitted')
    results.append((col, chi2, p))

# Convert results to a DataFrame for better visualization
results_df = pd.DataFrame(results, columns=['Variable', 'Chi-Square', 'p-value'])
significance_level = 0.05
results_df['Significant'] = results_df['p-value'] < significance_level
print(results_df)



###Model training

#Preparing X and Y values
X = df.drop('readmitted', axis=1)
y = df['readmitted']

# Encode the target variable to binary
y = y.map({'NO': 0, '<30': 1, '>30': 1})

# Create a variables
numeric_cols = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient']
categorical_cols = ['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'diag_1_category', 'diag_2_category', 'diag_3_category', 'diabetesMed', 'change']

# Ensure numeric columns are converted to numeric values and handle missing values
for col in numeric_cols:
    X[col] = X[col].astype(float)
    median_value = X[col].median()
    X[col] = X[col].fillna(median_value)

# Ensure categorical columns are converted to strings and handle missing values
for col in categorical_cols:
    X[col] = X[col].astype(str)
    mode_value = X[col].mode()[0]
    X[col].fillna(mode_value)    
    

# Create Column Transformer with 3 types of transformers
numeric_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

X = preprocessor.fit_transform(X)
X.shape

# Splitting data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the models to be evaluated
models = {
    'KNN': KNeighborsClassifier(),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'AdaBoost': AdaBoostClassifier(),
   # 'SVC': SVC(probability=True), # takes too long
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Ridge Classifier': RidgeClassifier()
}



# Function to train and evaluate models
def evaluate_models(models, X_train, y_train, X_test, y_test):
    results = {}
    for name, model in models.items():
        print(f"Training model: {name}")
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        y_pred_proba = None
        if hasattr(model, "predict_proba"):
            y_pred_proba = model.predict_proba(X_test)
            print(f"Model: {name}, y_pred_proba shape: {y_pred_proba.shape}, y_pred_proba type: {type(y_pred_proba)}")
        
        roc_auc = None
        if y_pred_proba is not None and y_pred_proba.ndim == 2:
            try:
                roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1])
            except ValueError as e:
                print(f"Model: {name}, Error in ROC-AUC calculation: {e}")

        results[name] = {
            'Accuracy': accuracy_score(y_test, y_pred),
            'Precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),
            'Recall': recall_score(y_test, y_pred, average='weighted'),
            'F1 Score': f1_score(y_test, y_pred, average='weighted'),
            'ROC-AUC': roc_auc
        }
        print(f"Results for model {name}: {results[name]}")
    return results

# Check the models dictionary
print("Models to evaluate:", list(models.keys()))

# Evaluate the models
results = evaluate_models(models, X_train, y_train, X_test, y_test)

# Convert results to DataFrame and display
results_df = pd.DataFrame(results).T
results_df

# Get the names of the transformed features
preprocessor.fit(X_train)
numeric_features = preprocessor.named_transformers_['num'].get_feature_names_out(numeric_cols)
categorical_features = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)

feature_names = list(numeric_features) + list(categorical_features)

# Train a Random Forest model
rf = RandomForestClassifier()
rf.fit(X_train, y_train)

# Get feature importances
importances = rf.feature_importances_

# Create a DataFrame for feature importances
feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

pd.set_option('display.max_rows', None)
feature_importance_df



# Fit and transform the data
X_transformed = preprocessor.fit_transform(X)

# Get feature names
numeric_features = preprocessor.named_transformers_['num'].get_feature_names_out(numeric_cols)
categorical_features = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)
feature_names = list(numeric_features) + list(categorical_features)

#RFE
model = LogisticRegression(max_iter=1000)

# Initialize RFE
rfe = RFE(estimator=model, n_features_to_select=10)  # Adjust the number of features to select

# Fit RFE
rfe.fit(X_train, y_train)

#Get the selected features
selected_features = [feature_names[i] for i in range(len(feature_names)) if rfe.support_[i]]
selected_features














# Outcome vs. Medication

#for col in medication_cols:
#    plt.figure(figsize=(10, 6))
#    sns.countplot(x=col, hue=outcome_col, data=df, edgecolor='black')
#    plt.title(f'{outcome_col} by {col}')
#    plt.xticks(rotation=45)
#    plt.show()

# Interactions Between Key Features
#interaction_cols = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications']
#sns.pairplot(df[interaction_cols])
#plt.show()

# Create a contingency table for primary diagnosis and readmission
contingency_table = pd.crosstab(df['diag_1_category'], df['readmitted'])

# Perform chi-square test
chi2, p, dof, expected = chi2_contingency(contingency_table)

print(f"Chi-square statistic: {chi2}")
print(f"p-value: {p}")

# Determine significance
alpha = 0.05
if p < alpha:
    print("There is a significant relationship between diagnosis category and readmission.")
else:
    print("There is no significant relationship between diagnosis category and readmission.")
    
    
print(f"Shape of y_pred_proba: {y_pred_proba.shape}")

# Function to train and evaluate models
def evaluate_models(models, X_train, y_train, X_test, y_test):
    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None
        results[name] = {
            'Accuracy': accuracy_score(y_test, y_pred),
            'Precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),
            'Recall': recall_score(y_test, y_pred, average='weighted'),
            'F1 Score': f1_score(y_test, y_pred, average='weighted'),
            'ROC-AUC': roc_auc_score(y_test, y_pred_proba, multi_class='ovr') if y_pred_proba is not None else None
        }
    return results

def evaluate_models(models, X_train, y_train, X_test, y_test):
    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        if hasattr(model, "predict_proba"):
            y_pred_proba = model.predict_proba(X_test)
            print(f"Model: {name}, y_pred_proba shape: {y_pred_proba.shape}, y_pred_proba type: {type(y_pred_proba)}")
            if y_pred_proba.ndim > 1 and y_pred_proba.shape[1] > 1:
                y_pred_proba = y_pred_proba[:, 1]
            roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')
        else:
            roc_auc = None
        results[name] = {
            'Accuracy': accuracy_score(y_test, y_pred),
            'Precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),
            'Recall': recall_score(y_test, y_pred, average='weighted'),
            'F1 Score': f1_score(y_test, y_pred, average='weighted'),
            'ROC-AUC': roc_auc
        }
    return results

# Evaluate the models
results = evaluate_models(models, X_train, y_train, X_test, y_test)

# Display the results
for model_name, metrics in results.items():
    print(f"Model: {model_name}")
    print(f"Accuracy: {metrics['Accuracy']:.4f}")
    print(f"Precision: {metrics['Precision']:.4f}")
    print(f"Recall: {metrics['Recall']:.4f}")
    print(f"F1 Score: {metrics['F1 Score']:.4f}")
    if metrics['ROC-AUC'] is not None:
        print(f"ROC-AUC: {metrics['ROC-AUC']:.4f}")
    print('-'*40)


##Building a model

numeric_cols = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient']
categorical_cols = ['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'diag_1_category', 'diag_2_category', 'diag_3_category', 'diabetesMed', 'change']

# Impute missing values for numeric columns
for col in numeric_cols:
    df[col] = df[col].astype(float)
    median_value = df[col].median()
    df[col] = df[col].fillna(median_value)


# Impute missing values for categorical columns
for col in categorical_cols:
    df[col] = df[col].astype(str)
    mode_value = df[col].mode()[0]
    df[col].fillna(mode_value)

# Encoding categorical variables
for col in categorical_cols:
    df[col] = LabelEncoder().fit_transform(df[col])

# Selecting features and target variable
features = numeric_cols + categorical_cols
target = 'readmitted'

X = df[features]
y = df[target]

# Splitting data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardizing numerical features
scaler = StandardScaler()
X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])

# Building and training the initial model
model = LogisticRegression(max_iter=1000, random_state=42)
model.fit(X_train, y_train)

# Evaluating the model
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)

# Ensure y_pred_proba is a 2D array
if y_pred_proba.ndim == 1 or y_pred_proba.shape[1] == 1:
    raise ValueError("The predicted probabilities array y_pred_proba must be a 2D array with probability scores for each class.")


# Calculate ROC-AUC Score for multi-class classification
roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nROC-AUC Score:")
print(roc_auc_score(y_test, y_pred_proba, multi_class='ovr'))



